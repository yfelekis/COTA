{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9640c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cvxpy as cp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from cvxpy.error import SolverError\n",
    "from cvxpy import ECOS, SCS\n",
    "import seaborn as sns\n",
    "import ot\n",
    "from pgmpy import inference\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "import scipy.optimize as optimize\n",
    "from scipy.spatial.distance import cdist\n",
    "from src.examples import smokingmodels as sm\n",
    "from scipy.spatial.distance import squareform,pdist\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "from scipy.optimize import linprog\n",
    "from scipy import stats\n",
    "from IPython.utils import io\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import distance\n",
    "from scipy.special import kl_div\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "from cvxpy.error import SolverError\n",
    "from cvxpy import ECOS, SCS\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from pgmpy import inference\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wasserstein_distance\n",
    "import scipy.optimize as optimize\n",
    "from scipy.spatial.distance import cdist\n",
    "from src.examples import smokingmodels as sm\n",
    "from scipy.spatial.distance import squareform,pdist\n",
    "from scipy.optimize import linprog\n",
    "from scipy import stats\n",
    "from IPython.utils import io\n",
    "import joblib\n",
    "from sklearn.linear_model import Lasso,LinearRegression\n",
    "\n",
    "import joblib\n",
    "import modularized_utils as ut\n",
    "import abstraction_metrics as ams\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "import cost_functions_utils as cts\n",
    "\n",
    "import get_results\n",
    "import params\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "np.set_printoptions(precision=4,suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea10587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "                1: 'synth1',\n",
    "                2: 'synth2',\n",
    "                3: 'synth1inv',\n",
    "                4: 'synthX1',\n",
    "                5: 'lucas',\n",
    "                6: 'little_lucas',\n",
    "                7: 'battery_discrete',\n",
    "                8: 'battery_continuous'\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c82dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comb(a, b, c):\n",
    "    return str(a)+'-'+str(b)+'-'+str(c)\n",
    "\n",
    "def parse_comb(input_string):\n",
    "    a, b, c = input_string.split('-')\n",
    "    return [float(a), float(b), float(c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89aab0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_grid(pairs, dropped_pair, experiment, combination, df, cf, cota_version):\n",
    "    \n",
    "    omega = {}\n",
    "    for pair in pairs:\n",
    "        omega[pair.iota_base] = pair.iota_abst\n",
    "    \n",
    "    hold_pairs = pairs.copy()\n",
    "   \n",
    "    if dropped_pair != None:\n",
    "        hold_pairs.remove(dropped_pair)\n",
    "        hold_omega  = ut.drop1omega(omega, dropped_pair.iota_base)\n",
    "        \n",
    "    else:\n",
    "        hold_omega = omega\n",
    "        \n",
    "    I_relevant  = list(hold_omega.keys())\n",
    "\n",
    "    struc, tree = ut.build_poset(I_relevant)\n",
    "    chains      = ut.to_chains(hold_pairs, struc)\n",
    "    \n",
    "    combin = parse_comb(combination)\n",
    "    kk, ll, mm = combin[0], combin[1], combin[2]\n",
    "    \n",
    "    args   = [hold_pairs, [chains], kk, ll, mm, df, cf]\n",
    "    \n",
    "    if cota_version == 'avg_plan':\n",
    "        get_results.results_grid_looo(args, experiment, dropped_pair)\n",
    "        looo_grid_results = ut.load_grid_results_looo(experiment, combination, dropped_pair)\n",
    "        \n",
    "    elif cota_version == 'avg_map':\n",
    "        get_results.results_grid_looo_aggregated(args, experiment, dropped_pair)\n",
    "        looo_grid_results = ut.load_grid_results_looo_aggregated(experiment, combination, dropped_pair)\n",
    "    \n",
    "    return looo_grid_results\n",
    "\n",
    "def compute_ae_grid_looo(exp, pairs, combo, metric, cost, cota_version):\n",
    "    \n",
    "    looo_results_grid = []\n",
    "    for n in range(len(pairs)):\n",
    "\n",
    "        results_grid = {}\n",
    "        for i, pair in enumerate(pairs[n]):\n",
    "\n",
    "            if pair.iota_base.intervention != {None: None}:\n",
    "                dropped_pair = pair\n",
    "            else:\n",
    "                dropped_pair = None\n",
    "\n",
    "            results_grid[dropped_pair] = leave_one_out_grid(pairs[n], dropped_pair, exp, combo, metric, cost, cota_version)\n",
    "\n",
    "        looo_results_grid.append(results_grid)\n",
    "    \n",
    "    return looo_results_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "88e94b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp      = experiments[7]\n",
    "pairs    = ut.load_pairs(exp)\n",
    "\n",
    "metric   = 'fro'\n",
    "cost     = 'Omega'\n",
    "\n",
    "error    = 'jsd'\n",
    "version  = 'avg_plan'\n",
    "combo    = '0.2-0.5-0.3'\n",
    "\n",
    "track_MI = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d7bd6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_matrix_lines_to_strings(matrix):\n",
    "    lines_as_strings = []\n",
    "    for line in matrix:\n",
    "        line_string = ''.join([str(int(element)) for element in line])\n",
    "        lines_as_strings.append(line_string)\n",
    "    return lines_as_strings\n",
    "\n",
    "def convert_list_to_matrix(strings_list):\n",
    "    matrix = []\n",
    "    for string in strings_list:\n",
    "        row = [float(char) for char in string]\n",
    "        matrix.append(row)\n",
    "    return np.array(matrix)\n",
    "\n",
    "def map_strings_to_values(strings_list, mapping_dict):\n",
    "    string_counts = Counter(strings_list)\n",
    "    new_dict = {}\n",
    "    for string in strings_list:\n",
    "        if string in mapping_dict:\n",
    "            value = mapping_dict[string]\n",
    "            count = string_counts[string]\n",
    "            new_dict[value] = [value] * count\n",
    "            \n",
    "    \n",
    "    res = [value for sublist in new_dict.values() for value in sublist]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c3d158ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_deter(tau, labels):# Initialize a dictionary to store the mappings of keys to labels with the highest probabilities\n",
    "    highest_prob_mappings = {}\n",
    "\n",
    "    # Iterate through each key in the stochastic mapping dictionary\n",
    "    for key, probabilities in tau.items():\n",
    "        # Check if the probability vector is the zero-vector\n",
    "        if all(p == 0.0 for p in probabilities):\n",
    "            # Choose a random index to select a label from l2\n",
    "            random_index = random.randint(0, len(labels) - 1)\n",
    "\n",
    "            # Get the corresponding label from l2 using the random index\n",
    "            corresponding_label = labels[random_index]\n",
    "        else:\n",
    "            # Find the index of the maximum probability\n",
    "            max_prob_index = probabilities.index(max(probabilities))\n",
    "\n",
    "            # Get the corresponding label from l2 using the index\n",
    "            corresponding_label = labels[max_prob_index]\n",
    "\n",
    "        # Store the mapping in the result dictionary\n",
    "        highest_prob_mappings[key] = corresponding_label\n",
    "\n",
    "    return highest_prob_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6e0ae830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_deter(tau, labels):# Initialize a dictionary to store the mappings of keys to labels with the highest probabilities\n",
    "    highest_prob_mappings = {}\n",
    "\n",
    "    # Iterate through each key in the stochastic mapping dictionary\n",
    "    for key, probabilities in tau.items():\n",
    "        # Check if the probability vector is the zero-vector\n",
    "        if all(p == 0.0 for p in probabilities):\n",
    "            min_dist  = np.inf\n",
    "            min_label = labels[random.randint(0, len(labels) - 1)]\n",
    "            for i, label in enumerate(labels):\n",
    "                dist = cts.hamming_distance(key, label)\n",
    "                \n",
    "                if dist<min_dist:\n",
    "                    min_dist = dist\n",
    "                    min_indx = i\n",
    "                    \n",
    "            # Get the corresponding label from l2 using the random index\n",
    "            corresponding_label = labels[min_indx]\n",
    "        else:\n",
    "            # Find the index of the maximum probability\n",
    "            max_prob_index = probabilities.index(max(probabilities))\n",
    "\n",
    "            # Get the corresponding label from l2 using the index\n",
    "            corresponding_label = labels[max_prob_index]\n",
    "\n",
    "        # Store the mapping in the result dictionary\n",
    "        highest_prob_mappings[key] = corresponding_label\n",
    "\n",
    "    return highest_prob_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ce1c7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = joblib.load('data/battery_discrete/df_baseB.pkl')\n",
    "df_abst = joblib.load('data/battery_discrete/df_abstB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "555bb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "labels.append(pairs[0][0].base_labels)\n",
    "labels.append(pairs[0][0].abst_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d0aaddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compute_ae_grid_looo(exp, pairs, combo, metric, cost, version)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d4f68434",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts       = convert_matrix_lines_to_strings(df_base.values)\n",
    "tau_detrm = make_deter(res[None][0], labels[1])\n",
    "\n",
    "formatted_tau_dict = {\n",
    "    ''.join(map(str, key)): ''.join(map(str, value)) for key, value in tau_detrm.items()\n",
    "}\n",
    "tau_samples = convert_list_to_matrix(map_strings_to_values(sts, formatted_tau_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "076d1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_df = pd.DataFrame(tau_samples, columns=df_abst.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9beaeae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_abst = pd.concat([df_abst, tau_df], ignore_index=True) #enhanced_abst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e0107fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "swap = {0: 75, 1: 100, 2: 200}\n",
    "\n",
    "df_abst['Comma gap (µm)'] = df_abst['Comma gap (µm)'].replace(swap)\n",
    "enhanced_abst = pd.concat([df_abst, tau_df], ignore_index=True)\n",
    "enhanced_abst['Comma gap (µm)'] = enhanced_abst['Comma gap (µm)'].replace(swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c54d5d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_CG_LRCS = len(df_abst['Comma gap (µm)'].unique())\n",
    "n_ML_LRCS = 5\n",
    "dom_CG_LRCS = list(set(df_abst['Comma gap (µm)'].values)) # [75,100,200]\n",
    "dom_ML_LRCS = np.arange(n_ML_LRCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "583752d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(model,Xte,yte,Xout,roundpred=True):\n",
    "    if roundpred:\n",
    "        preds = np.round(model.predict(Xte.reshape(-1,1)))\n",
    "    else:\n",
    "        preds = model.predict(Xte.reshape(-1,1))\n",
    "    mses = (preds - yte)**2\n",
    "    print('MSE (with {0} out): {1} ({2})'.format(Xout,np.mean(mses),np.std(mses)))\n",
    "    print('${0:.2f}\\pm{1:.2f}$'.format(np.mean(mses),np.std(mses)))\n",
    "    \n",
    "    return np.mean(mses)\n",
    "\n",
    "def select_one_X_out(X,y,cond):\n",
    "    Xte = np.array(X[cond])\n",
    "    yte = np.array(y[cond])\n",
    "\n",
    "    Xtr = np.array(X[np.logical_not(cond)])\n",
    "    ytr = np.array(y[np.logical_not(cond)])\n",
    "    \n",
    "    return Xtr,ytr,Xte,yte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2e0ec",
   "metadata": {},
   "source": [
    "## Before abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3c640546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (with 200 out): 3.358400000000001 (0.9112079894294169)\n",
      "$3.36\\pm0.91$\n",
      "MSE (with 75 out): 0.6362090277777774 (0.7281328087325675)\n",
      "$0.64\\pm0.73$\n",
      "MSE (with 100 out): 0.21659716000000065 (0.0)\n",
      "$0.22\\pm0.00$\n",
      "Overall MSE: 1.4037353959259262 (1.392732043074578)\n",
      "$1.40\\pm1.39$\n"
     ]
    }
   ],
   "source": [
    "#Lasso\n",
    "scores_a = []\n",
    "\n",
    "for cg in dom_CG_LRCS:\n",
    "    cond = df_abst['Comma gap (µm)']==cg\n",
    "    \n",
    "    Xtr,ytr,Xte,yte = select_one_X_out(df_abst['Comma gap (µm)'],df_abst['binned ML'],cond)\n",
    "    model = Lasso().fit(Xtr.reshape(-1,1),ytr)\n",
    "    score = eval_metric(model,Xte,yte,cg,False)\n",
    "    scores_a.append(score)\n",
    "    \n",
    "print('Overall MSE: {0} ({1})'.format(np.mean(scores_a),np.std(scores_a)))\n",
    "print('${0:.2f}\\pm{1:.2f}$'.format(np.mean(scores_a),np.std(scores_a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c7a1b",
   "metadata": {},
   "source": [
    "## After abstraction\n",
    "\n",
    "Learning on LRCS+WMG data: one-X out with WMG providing the missing support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "649823fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (with 200 out): 0.04152396170310105 (0.16722099024356046)\n",
      "$0.04\\pm0.17$\n",
      "MSE (with 75 out): 0.2503504775522152 (0.49638727062556837)\n",
      "$0.25\\pm0.50$\n",
      "MSE (with 100 out): 0.08763420978073998 (0.0)\n",
      "$0.09\\pm0.00$\n",
      "Overall MSE: 0.12650288301201873 (0.08957383825459315)\n",
      "$0.13\\pm0.09$\n"
     ]
    }
   ],
   "source": [
    "scores_b = []\n",
    "\n",
    "for cg in dom_CG_LRCS:\n",
    "    cond0 = df_abst['Comma gap (µm)']==cg\n",
    "    cond1 = list(cond0) + [False]*(len(enhanced_abst)-len(cond0))\n",
    "    \n",
    "    Xtr,ytr,Xte,yte = select_one_X_out(enhanced_abst['Comma gap (µm)'],enhanced_abst['binned ML'],cond1)\n",
    "    \n",
    "    model = Lasso().fit(Xtr.reshape(-1,1),ytr)\n",
    "    score = eval_metric(model,Xte,yte,cg,False)\n",
    "    scores_b.append(score)\n",
    "    \n",
    "print('Overall MSE: {0} ({1})'.format(np.mean(scores_b),np.std(scores_b)))\n",
    "print('${0:.2f}\\pm{1:.2f}$'.format(np.mean(scores_b),np.std(scores_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6056660b",
   "metadata": {},
   "source": [
    "Learning on LRCS+WMG data: one X-out with WMG not providing the missing support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "61f47705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (with 200 out): 0.6897503886465074 (0.9111193121851174)\n",
      "$0.69\\pm0.91$\n",
      "MSE (with 75 out): 0.671449079188327 (0.8063169776084173)\n",
      "$0.67\\pm0.81$\n",
      "MSE (with 100 out): 0.33602740343770643 (0.6617402485215056)\n",
      "$0.34\\pm0.66$\n",
      "Overall MSE: 0.5657422904241803 (0.1626046974708446)\n",
      "$0.57\\pm0.16$\n"
     ]
    }
   ],
   "source": [
    "scores_c = []\n",
    "\n",
    "for cg in dom_CG_LRCS:\n",
    "    cond = enhanced_abst['Comma gap (µm)']==cg\n",
    "    \n",
    "    Xtr,ytr,Xte,yte = select_one_X_out(enhanced_abst['Comma gap (µm)'],enhanced_abst['binned ML'],cond)\n",
    "    \n",
    "    model = Lasso().fit(Xtr.reshape(-1,1),ytr)\n",
    "    score = eval_metric(model,Xte,yte,cg,False)\n",
    "    scores_c.append(score)\n",
    "    \n",
    "print('Overall MSE: {0} ({1})'.format(np.mean(scores_c),np.std(scores_c)))\n",
    "print('${0:.2f}\\pm{1:.2f}$'.format(np.mean(scores_c),np.std(scores_c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c65bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
